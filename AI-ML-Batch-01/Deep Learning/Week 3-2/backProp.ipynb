{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNn0DXHkaC_O"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "data = torch.tensor([\n",
        "    [2.0, 40.0, 45.0],   # studied 2 hrs, practice 40 â†’ exam 45\n",
        "    [5.0, 60.0, 65.0],\n",
        "    [7.0, 80.0, 85.0],\n",
        "    [1.0, 30.0, 35.0]\n",
        "])\n",
        "\n",
        "X = data[:,0:2]\n",
        "y= data[:,2].reshape(-1,1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 inputs\n",
        "2 hidden layer neurons"
      ],
      "metadata": {
        "id": "k64ST1UXiszW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w1 = torch.randn(2,2, requires_grad=True)\n",
        "w1.data*=0.1\n",
        "\n",
        "b1 = torch.zeros(1,2, requires_grad=True)\n",
        "\n",
        "w2 = torch.randn(2,1, requires_grad=True)\n",
        "w2.data*=0.1\n",
        "\n",
        "b2 = torch.zeros(1,1, requires_grad=True)"
      ],
      "metadata": {
        "id": "JZRjE5xTikuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "forward pass"
      ],
      "metadata": {
        "id": "EcRuykYLjy1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(X):\n",
        "  A1 = X @ w1 + b1\n",
        "  A2 = A1 @ w2 + b2\n",
        "\n",
        "  return A2"
      ],
      "metadata": {
        "id": "EdSvwvCgj1q8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss Function"
      ],
      "metadata": {
        "id": "f-1mDGaKly6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(y_pred, y):\n",
        "  return ((y_pred - y)**2).mean()"
      ],
      "metadata": {
        "id": "7BvU6Ym7l6yC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Backprop loop"
      ],
      "metadata": {
        "id": "8zjoMOUKmn1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr= 0.0001\n",
        "\n",
        "for epoch in range(50):\n",
        "  y_pred = forward(X)\n",
        "  loss = loss_fn(y_pred,y)\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "    w1 -= lr * w1.grad\n",
        "    w2 -= lr * w2.grad\n",
        "\n",
        "    b1 -= lr * b1.grad\n",
        "    b2 -= lr * b2.grad\n",
        "\n",
        "    w1.grad.zero_()\n",
        "    w2.grad.zero_()\n",
        "    b1.grad.zero_()\n",
        "    b2.grad.zero_()\n",
        "\n",
        "  print(f\"epoch: {epoch} loss: {loss.item()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjRvbw_dmqmd",
        "outputId": "475903f6-cc47-4b21-f17b-687024e54d84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0 loss: 3674.038818359375\n",
            "epoch: 1 loss: 3653.39990234375\n",
            "epoch: 2 loss: 3613.65673828125\n",
            "epoch: 3 loss: 3507.60888671875\n",
            "epoch: 4 loss: 3226.429931640625\n",
            "epoch: 5 loss: 2545.317626953125\n",
            "epoch: 6 loss: 1279.5850830078125\n",
            "epoch: 7 loss: 144.03639221191406\n",
            "epoch: 8 loss: 7.294680595397949\n",
            "epoch: 9 loss: 4.058391571044922\n",
            "epoch: 10 loss: 3.557847261428833\n",
            "epoch: 11 loss: 3.4969844818115234\n",
            "epoch: 12 loss: 3.48751163482666\n",
            "epoch: 13 loss: 3.484829902648926\n",
            "epoch: 14 loss: 3.4830126762390137\n",
            "epoch: 15 loss: 3.4813036918640137\n",
            "epoch: 16 loss: 3.4796032905578613\n",
            "epoch: 17 loss: 3.477916955947876\n",
            "epoch: 18 loss: 3.4762344360351562\n",
            "epoch: 19 loss: 3.474543333053589\n",
            "epoch: 20 loss: 3.4728469848632812\n",
            "epoch: 21 loss: 3.471156597137451\n",
            "epoch: 22 loss: 3.4694674015045166\n",
            "epoch: 23 loss: 3.4677937030792236\n",
            "epoch: 24 loss: 3.466104030609131\n",
            "epoch: 25 loss: 3.4644322395324707\n",
            "epoch: 26 loss: 3.462740421295166\n",
            "epoch: 27 loss: 3.4610562324523926\n",
            "epoch: 28 loss: 3.4593870639801025\n",
            "epoch: 29 loss: 3.4577062129974365\n",
            "epoch: 30 loss: 3.456021785736084\n",
            "epoch: 31 loss: 3.454348564147949\n",
            "epoch: 32 loss: 3.4526619911193848\n",
            "epoch: 33 loss: 3.4509990215301514\n",
            "epoch: 34 loss: 3.449321985244751\n",
            "epoch: 35 loss: 3.447652816772461\n",
            "epoch: 36 loss: 3.445976734161377\n",
            "epoch: 37 loss: 3.4442973136901855\n",
            "epoch: 38 loss: 3.4426233768463135\n",
            "epoch: 39 loss: 3.440958261489868\n",
            "epoch: 40 loss: 3.43928861618042\n",
            "epoch: 41 loss: 3.4376220703125\n",
            "epoch: 42 loss: 3.435957908630371\n",
            "epoch: 43 loss: 3.4342966079711914\n",
            "epoch: 44 loss: 3.4326229095458984\n",
            "epoch: 45 loss: 3.43096923828125\n",
            "epoch: 46 loss: 3.4292941093444824\n",
            "epoch: 47 loss: 3.42763614654541\n",
            "epoch: 48 loss: 3.425966262817383\n",
            "epoch: 49 loss: 3.4243016242980957\n"
          ]
        }
      ]
    }
  ]
}